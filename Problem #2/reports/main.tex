\documentclass[11pt]{article}

\usepackage[margin=1in]{geometry}
\usepackage{amsmath,amssymb}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{xurl}
\usepackage[breaklinks]{hyperref}
\usepackage{enumitem}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{siunitx}
\usepackage{longtable}
\usepackage[numbers]{natbib}
\let\origthebibliography\thebibliography
\renewcommand{\thebibliography}[1]{\origthebibliography{#1}\sloppy}

\hypersetup{colorlinks=true, linkcolor=blue, urlcolor=blue, citecolor=blue}
\sisetup{detect-weight=true, detect-family=true}

% ---------- Convenience macros ----------
\newcommand{\NetRisk}{\ensuremath{\mathrm{NetRisk}}}
\newcommand{\SubScore}{\ensuremath{\mathrm{Sub}}}
\newcommand{\DefScore}{\ensuremath{\mathrm{Def}}}
\newcommand{\Emp}[1]{E_{#1}} % employment level at year
\newcommand{\gbase}{g_{\mathrm{base}}}
\newcommand{\gadj}{g_{\mathrm{adj}}}

% ---------- Auto-generated tables/figures (from build_report_artifacts.py) ----------
% NOTE: these files contain full LaTeX environments, so they must be \input
% inside the document body (not in the preamble).

\title{ICM 2026 Problem F: To Gen-AI, or Not To Gen-AI?\\
\large A data-informed model of GenAI exposure and institution-specific educational recommendations}
\author{Team \#\_\_\_\_}
\date{}

\begin{document}
\sloppy
\maketitle

% ============================================================
% 1) One-page Summary Sheet (written last; placed first)
% ============================================================
\section*{Summary Sheet}
\begin{itemize}[leftmargin=*]
  \item \textbf{Careers and institutions.} We study a STEM career (Software Developers; San Diego State University), a trade career (Electricians; Los Angeles Trade--Technical College), and an arts career (Writers and Authors; Academy of Art University).
  \item \textbf{Data.} We combine BLS Occupational Employment and Wage Statistics (OEWS) for local labor market context with BLS Employment Projections (EP) for national 2024--2034 baselines, and O*NET 30.1 descriptors to build a mechanism layer explaining substitution vs.\ complementarity \citep{bls_oews_tec, bls_ep_table110, onet_database, onet_taxonomy, onet_license}.
  \item \textbf{Model.} We define five O*NET-based dimensions, compute percentiles across occupations, and form a \emph{Net Risk} index:
  \[
    \NetRisk = \underbrace{\frac{\mathrm{Writing} + \mathrm{ToolTech}}{2}}_{\SubScore} - \underbrace{\frac{\mathrm{Physical} + \mathrm{Social} + \mathrm{Creativity}}{3}}_{\DefScore}.
  \]
  Scenario employment uses baseline EP annual growth \(\gbase\) adjusted by a scenario parameter \(s\) using a piecewise mapping: 
  \[
    \gadj = \gbase - s \cdot \max(\NetRisk, 0) + 0.2 s \cdot \max(-\NetRisk, 0).
  \]
  This effectively creates a substitution penalty for exposed occupations while capping the complementarity uplift for sheltered occupations to 20\% of the shock magnitude. See Table~\ref{tab:scenario_summary}.
  \item \textbf{Headline findings (national 2034).} Under immediate High disruption vs.\ baseline, employment shifts by: Software Developers \(1.96\text{M}\rightarrow 1.40\text{M}\) (-556k), Electricians \(0.90\text{M}\rightarrow 0.96\text{M}\) (+61k), Writers and Authors \(140\text{k}\rightarrow 111\text{k}\) (-29k). Ramp scenarios reduce the magnitude of disruption (Table~\ref{tab:scenario_summary}).\par
  \textbf{Interpretation:} positive \(\NetRisk\) implies GenAI is more substitutive, so curricula should emphasize verification, evaluation, and higher-level judgment; negative \(\NetRisk\) implies sheltering, so curricula should emphasize safe, tool-assisted workflows that augment practice.
  \item \textbf{Program-size decisions.} SDSU CS: maintain/slight growth; LATTC Electric: grow aggressively; Academy of Art Writing: consolidate/specialize toward higher-originality niches and editing/production workflows (Section~\ref{sec:recommendations}).
  \item \textbf{Key limitations.} Scenarios treat \(s\) as a transparent stress-test knob (not a causal estimate); career--occupation mapping uses small SOC bundles with employment-weighted aggregation; local program sizing uses scaled openings as a proxy (Section~\ref{sec:robustness}).
\end{itemize}
\newpage

% ============================================================
% Table of Contents (required)
% ============================================================
\tableofcontents
\newpage

% ============================================================
% Main report
% ============================================================
\section{Problem framing and choices}
\label{sec:framing}
We aim to advise leaders of three post-secondary programs on how to address GenAI, using an auditable model grounded in public labor-market data and an explainable O*NET mechanism layer. Our framing follows tasks-based technology theories: GenAI can substitute for some language/cognitive tasks while complementing others, changing task composition and productivity rather than deterministically eliminating whole occupations \citep{mit_tasks_based_framing, openai_llm_exposure, nber_generative_ai_at_work}. We choose the three careers to match the prompt's STEM/trade/arts categories and to span a wide range of task structures (software = tool/knowledge work; electricians = physical/manual, onsite; writers = writing-intensive creative production).

\section{Data and preprocessing}
\label{sec:data}
\subsection{BLS OEWS (local labor market context)}
OEWS provides local (state and metropolitan) employment and wage levels for occupations. We use these as the institution-specific context inputs: the `local'' employment level and wages for each program's regional labor market \citep{bls_oews_tec}.

\subsection{BLS Employment Projections (national baseline trend)}
EP provides national occupational employment projections over 2024--2034, which we convert to an annual baseline growth rate \(\gbase\). National trajectories use EP (all jobs) for consistency with baseline growth rates; OEWS (wage-and-salary) is used for local labor-market context. We use EP as the no-GenAI baseline trajectory for each focal career (aggregating across the SOCs in its bundle) \citep{bls_ep_table110}.

\subsection{O*NET mechanism layer (why substitution vs.\ complementarity)}
We use O*NET 30.1 `Importance'' ratings from Work Activities, Abilities, and Skills to construct five dimensions. We compute each dimension score per occupation and convert to a percentile across occupations (0--1). This produces interpretable inputs for \(\NetRisk\) \citep{onet_database, onet_taxonomy, onet_license}.

\paragraph{Attribution.} O*NET\textsuperscript{\textregistered} data used under the O*NET Database Content License; see References \citep{onet_license}.

\subsection{Crosswalks and coverage (what gets dropped)}
Occupational taxonomies differ between OEWS/EP (SOC-based) and O*NET (O*NET-SOC). We align them at the SOC occupation code level used in BLS tables by slicing O*NET-SOC codes (e.g., \texttt{15-1252.00}) to their 7-character SOC stem (e.g., \texttt{15-1252}). This merges multiple O*NET-SOC specialties into one SOC occupation, which is appropriate because BLS publishes OEWS/EP at the SOC level.\par
Not every SOC appears in every data source: some SOC codes present in O*NET do not appear in OEWS or EP tables (and vice versa), and some are aggregation/detail differences. Table~\ref{tab:mechanism_coverage} reports counts at each stage (O*NET-SOC $\to$ SOC slice $\to$ relevant elements $\to$ mechanism-scored occupations $\to$ overlap with OEWS/EP) so that any `dropped'' occupations are transparent and auditable.

\IfFileExists{tables/mechanism_coverage.tex}{\input{tables/mechanism_coverage.tex}}{}

\section{Model}
\label{sec:model}
\subsection{Mechanism dimensions}
Let \(d\in\{\mathrm{Writing},\mathrm{ToolTech},\mathrm{Physical},\mathrm{Social},\mathrm{Creativity}\}\) be the five dimensions. For each occupation \(i\), we compute a raw mean importance score from selected O*NET elements, then convert to a percentile across the occupation set:
\[
  x_{i,d} \in [0,1] \quad \text{(percentile among occupations)}.
\]

\subsection{Net Risk index}
Define substitution and defense scores:
\[
  \SubScore_i = \frac{x_{i,\mathrm{Writing}} + x_{i,\mathrm{ToolTech}}}{2}, \qquad
  \DefScore_i = \frac{x_{i,\mathrm{Physical}} + x_{i,\mathrm{Social}} + x_{i,\mathrm{Creativity}}}{3},
\]
and \(\NetRisk_i = \SubScore_i - \DefScore_i\). Positive \(\NetRisk\) implies higher exposure to substitution; negative \(\NetRisk\) implies relative sheltering/complementarity.

Table~\ref{tab:netrisk_summary} provides summary statistics for the \NetRisk{} distribution across all scored occupations, and the interpretation examples below illustrates the interpretation by listing extreme examples from both tails of the distribution.

\IfFileExists{tables/netrisk_summary.tex}{\input{tables/netrisk_summary.tex}}{}
\IfFileExists{tables/netrisk_interpretation.tex}{\input{tables/netrisk_interpretation.tex}}{}

\begin{figure}[H]
\centering
\includegraphics[width=0.9\linewidth]{figures/netrisk_hist.png}
\caption{Distribution of NetRisk scores across all occupations in the mechanism layer (from \texttt{data/mechanism\_risk\_scored.csv}).}
\label{fig:netrisk_hist}
\end{figure}

\subsection{External calibration to AI applicability}
To improve rigor, we calibrate the mechanism weights against an external occupation-level AI applicability measure from the \emph{Working with AI} dataset (Tomlinson et al., 2025), which provides SOC-level applicability scores derived from real-world GenAI usage patterns \citep{tomlinson2025working}. We fit nonnegative weights on the five dimensions with defense dimensions entering with negative sign. Because the five dimensions are correlated, the nonnegativity constraint can yield sparse solutions (some weights at or near zero), which should be interpreted as ``adds little predictive power given the other dimensions'' rather than ``dimension is irrelevant.''\par
In other words, multiple dimensions can be jointly informative but redundant: when two percentile features move together across occupations, the constrained fit may assign weight primarily to one and drive the other toward zero without meaning that the underlying mechanism is absent. To guard against over-interpreting a single fitted weight vector, we include a simple weight-robustness check (Table~\ref{tab:weight_sensitivity}).\par
The calibrated weights define a calibrated \(\NetRisk\) by taking the weighted signed sum, centering it to mean zero across occupations, and rescaling to approximately \([-1,1]\). When calibration outputs are available, the pipeline uses this calibrated \(\NetRisk\) in downstream scenario projections; otherwise it uses the uncalibrated index defined in Section~3.2.

\IfFileExists{tables/calibration_summary.tex}{\input{tables/calibration_summary.tex}}{}

\begin{figure}[H]
\centering
\includegraphics[width=0.6\linewidth]{figures/calibration_scatter.png}
\caption{Calibration fit: observed vs.\ predicted AI applicability (from \texttt{data/calibration\_fit.csv}).}
\label{fig:calibration_scatter}
\end{figure}

\subsection{Scenario employment projection}
Let \(\Emp{2024}\) be the 2024 employment level used for the projection base (from BLS EP for national scenarios) and \(\gbase\) the EP annual baseline growth. OEWS is used for \emph{local} labor market context and program sizing (Section~\ref{sec:recommendations}). For a scenario parameter \(s\ge 0\), define adjusted growth:
\[
  \gadj = \begin{cases} 
    \gbase - s \cdot \NetRisk & \text{if } \NetRisk \ge 0 \\
    \gbase + 0.2 s \cdot (-\NetRisk) & \text{if } \NetRisk < 0 
  \end{cases}
\]
Scenario strengths are defined by a reference-point calibration: we target a growth headwind of 1.5\% (Moderate) or 3\% (High) for the 90th percentile of the \emph{positive} \(\NetRisk\) distribution. Concretely, the pipeline computes \(p90(\NetRisk_+)\) from the calibrated mechanism layer, then sets
\[
  s_{\text{Moderate}} = 0.015 / p90(\NetRisk_+), \qquad s_{\text{High}} = 0.03 / p90(\NetRisk_+),
\]
so that the 90th-percentile exposed occupation experiences the intended annual headwind under the piecewise mapping. Table~\ref{tab:scenario_params} reports the scenario parameters actually used (including whether they came from calibration outputs or defaults). The factor \(0.2\) scales complementarity: while GenAI may help sheltered occupations, we assume the demand boost is smaller than the substitution effect for exposed ones. We project 2034 employment as \(\Emp{2034} = \Emp{2024}(1+\gadj)^{10}\). We treat \(s\) as a scenario knob rather than an estimated causal effect; Section~\ref{sec:robustness} reports a sensitivity grid.

\IfFileExists{tables/scenario_params.tex}{\input{tables/scenario_params.tex}}{}

\section{Results}
\label{sec:results}
\subsection{National outcomes for the three careers}
Each career is represented by a small bundle of SOC occupations (e.g., 2--3 codes per career); outcomes are employment-weighted over the bundle so that larger occupations contribute more to the career-level projection. Table~\ref{tab:scenario_summary} reports baseline vs.\ disruption outcomes and the \(\NetRisk\) range (min--max across the bundle) as a robustness check.

\IfFileExists{tables/scenario_summary.tex}{\input{tables/scenario_summary.tex}}{}

\begin{figure}[H]
\centering
\includegraphics[width=0.9\linewidth]{figures/scenario_bar.png}
\caption{2034 employment for the three careers under baseline, moderate, and high disruption (generated from \texttt{data/scenario\_summary.csv}).}
\label{fig:scenario_bar}
\end{figure}

\subsection{Dynamic Adoption}
The scenarios above assume immediate adoption of GenAI at full impact. In reality, adoption may ramp gradually over the decade. Table~\ref{tab:scenario_summary} includes `Ramp Moderate'' and `Ramp High'' scenarios that model gradual adoption, where disruption effects increase linearly from zero in 2024 to full scenario strength by 2034. Across all three careers, the ramp outcomes lie between the baseline and immediate-disruption outcomes reported in Table~\ref{tab:scenario_summary}, consistent with a gradual diffusion of GenAI impacts over time. These ramp scenarios suggest that institutions have a window to adapt curricula and program structures as adoption accelerates, rather than facing immediate disruption.

\subsection{Job openings and program sizing}
Beyond net employment growth, annual job openings drive training demand. Table~\ref{tab:openings_summary} reports annual openings from EP projections and their implications for program sizing decisions.

\IfFileExists{tables/openings_summary.tex}{\input{tables/openings_summary.tex}}{}

\subsection{Sensitivity and sanity checks}
\label{sec:robustness}
We conduct extensive robustness checks to validate the stability of our model components.

\subsubsection{Mechanism Layer Stability}
The O*NET mechanism layer relies on specific descriptor choices and normalization methods. To test structural stability, we perturbed the descriptor set (leave-one-out) and tested alternative normalization (z-scores vs.\ percentiles). Table~\ref{tab:mechanism_sensitivity} summarizes the results: the sign of \(\NetRisk\) for our three focal careers remains stable across perturbations, confirming that the classification of careers as ``exposed'' vs.\ ``sheltered'' is not an artifact of specific element selection.

\IfFileExists{tables/mechanism_sensitivity.tex}{\input{tables/mechanism_sensitivity.tex}}{}

\subsubsection{Calibration Validation}
We validate the calibration weights using 5-fold cross-validation and bootstrap resampling (Table~\ref{tab:calibration_validation}). The model achieves stable out-of-sample performance, and bootstrap analysis confirms that the negative weights on defense dimensions are statistically robust. We also compare the calibrated index against an uncalibrated (equal-weight) baseline; the ranking of focal careers is preserved, though the magnitude of separation increases under calibration.

\IfFileExists{tables/calibration_validation.tex}{\input{tables/calibration_validation.tex}}{}

\subsubsection{Scenario and Parameter Sensitivity}
We include three compact robustness checks for the scenario projections: (i) a sensitivity grid over plausible \(s\) values (Table~\ref{tab:sensitivity_grid}); (ii) a sanity-check table listing the most exposed and most sheltered occupations by \(\NetRisk\) in the full scored set (Table~\ref{tab:top_exposed_sheltered}); and (iii) Monte Carlo uncertainty intervals for 2034 employment under Moderate and High disruption (Table~\ref{tab:uncertainty_summary}).
These checks highlight that while the exact 2034 employment level depends on \(s\), the \emph{direction} of impact is structurally determined by the mechanism layer.

\IfFileExists{tables/sensitivity_grid.tex}{\input{tables/sensitivity_grid.tex}}{}
\IfFileExists{tables/comp_factor_sensitivity.tex}{\input{tables/comp_factor_sensitivity.tex}}{}
\IfFileExists{tables/weight_sensitivity.tex}{\input{tables/weight_sensitivity.tex}}{}
\IfFileExists{tables/top_exposed_sheltered.tex}{\input{tables/top_exposed_sheltered.tex}}{}
\IfFileExists{tables/uncertainty_summary.tex}{\input{tables/uncertainty_summary.tex}}{}

\section{Institution-specific recommendations}
\label{sec:recommendations}
Recommendations are organized to answer the prompt: (i) whether to grow or shrink program size and how, and (ii) what to teach about GenAI to best support employability, tied back to model outputs and local context.

Table~\ref{tab:local_context} provides local labor market context including location quotients (LQ). We define an auxiliary \textit{Attractiveness Score} to inform positioning:
\[ \text{Attractiveness} = 0.4 \cdot (\text{Wage Premium}) + 0.3 \cdot (\text{Normalized Local Emp}) + 0.3 \cdot (\text{Normalized LQ}) \]
where normalized employment and LQ are min-max scaled across the three institutions. Table~\ref{tab:program_sizing} provides quantitative guidance on program sizing (annual intake) derived from estimated local annual openings. To account for uncertainty in program efficiency (completion rates and placement rates), we report recommended intake ranges rather than single point estimates.

\IfFileExists{tables/local_context.tex}{\input{tables/local_context.tex}}{}
\IfFileExists{tables/program_sizing.tex}{\input{tables/program_sizing.tex}}{}

\subsection{SDSU (Software Developers)}
\textbf{Program size.} Maintain or modestly grow cohorts; disruption primarily reduces growth rate rather than reversing demand (Table~\ref{tab:scenario_summary}).\par
\textbf{Curriculum.} Shift emphasis from boilerplate coding to system design, testing, security, and AI-assisted development with audit trails; make students fluent in evaluating and verifying model outputs.\par
\textbf{Policy.} Permit GenAI use in advanced courses with required disclosure and reproducibility; constrain use in early courses to ensure fundamentals.
\par\textbf{Concrete actions (measurable).}
\begin{itemize}[leftmargin=*]
  \item \textbf{AI-assisted software engineering rubric.} Require every capstone/upper-division project to include (i) tests and CI, (ii) a model-output verification checklist, and (iii) an AI usage disclosure appendix.\newline
  \emph{Metric:} \% of submissions with passing test suites; defect rate in instructor code review; disclosure compliance rate.
  \item \textbf{Model evaluation and security module.} Add a short required module on prompt injection, data leakage, licensing/IP, and evaluation design.\newline
  \emph{Metric:} performance on a standardized red-team + verification assessment (before/after module).
  \item \textbf{Assessment design resilient to GenAI.} Increase oral defenses and timed debugging tasks in core courses.\newline
  \emph{Metric:} gap between in-person performance and take-home performance (reduced variance indicates more robust assessment).
\end{itemize}

\subsection{LATTC (Electricians)}
\textbf{Program size.} Grow capacity and apprenticeship pathways; the career is sheltered by high physical/manual defense and remains strong across scenarios (Table~\ref{tab:scenario_summary}).\par
\textbf{Curriculum.} Double down on hands-on competencies while adding `AI as a tool'' modules for diagnostics, scheduling, documentation, and code-compliant planning.\par
\textbf{Policy.} Teach safe, privacy-preserving, low-compute uses (templates, checklists) appropriate for small contractors.
\par\textbf{Concrete actions (measurable).}
\begin{itemize}[leftmargin=*]
  \item \textbf{AI-assisted job documentation.} Require students to produce work orders, inspection-ready notes, and material lists using structured templates (GenAI optional) with verification against NEC/local code excerpts.\newline
  \emph{Metric:} documentation completeness score; code-compliance error rate on practical exams.
  \item \textbf{Diagnostic reasoning labs.} Use fault-tree exercises where students must justify each step (GenAI permitted as a tutor, not as an answer key).\newline
  \emph{Metric:} time-to-diagnosis and accuracy on standardized fault scenarios; safety-critical mistake rate.
  \item \textbf{Apprenticeship alignment.} Expand employer partnerships to target annual seats suggested by local openings (Table~\ref{tab:program_sizing}).\newline
  \emph{Metric:} placement rate into apprenticeships; employer satisfaction survey on graduates' documentation and troubleshooting skills.
\end{itemize}

\subsection{Academy of Art University (Writers and Authors)}
\textbf{Program size.} Consolidate and specialize toward higher-originality work and editing/production roles; high disruption can flip the field to contraction (Table~\ref{tab:scenario_summary}).\par
\textbf{Curriculum.} Emphasize narrative strategy, editing, and provenance-aware workflows. Teach students to use GenAI as a draft accelerator while differentiating through voice, revision quality, and IP-aware sourcing.\par
\textbf{Policy.} Require disclosure and provenance in portfolios; adopt rubrics that reward originality and documented creative process.
\par\textbf{Concrete actions (measurable).}
\begin{itemize}[leftmargin=*]
  \item \textbf{Portfolio provenance standard.} Require every portfolio piece to include a process log (outline $\to$ drafts $\to$ revisions) and a disclosure statement for any tool-assisted content.\newline
  \emph{Metric:} \% of portfolio pieces with complete provenance; rubric scores on originality/voice and revision quality.
  \item \textbf{Editing and production track.} Create an explicit concentration in editing, story development, and content production workflows where human judgment is primary.\newline
  \emph{Metric:} internship/placement share into editing, producer-assistant, UX/technical writing, or content operations roles.
  \item \textbf{Assessment designed for authenticity.} Use in-class writing sprints and oral defenses (students explain intent, sources, and revision decisions).\newline
  \emph{Metric:} integrity-incident rate; inter-rater reliability of originality scoring.
\end{itemize}

\subsubsection{Transition Plan}
For students currently enrolled in the Writers and Authors program, we recommend redirecting to absorber programs with lower \NetRisk{} due to higher tool complementarity and stronger defense dimensions. Specific transition pathways include:

\begin{itemize}[leftmargin=*]
  \item \textbf{UX Writing.} Redirect students toward user experience writing programs, which exhibit lower \NetRisk{} due to higher \DefScore{} components: elevated Social dimension (user research, cross-functional collaboration) and Creativity dimension (design thinking, user-centered storytelling). The Writing component remains relevant but is complemented by collaborative and research-intensive workflows that GenAI augments rather than substitutes.
  
  \item \textbf{Technical Communication.} Transition students to technical communication programs, which show reduced \NetRisk{} through higher Social dimension scores (stakeholder communication, documentation for diverse audiences) and ToolTech complementarity (GenAI assists in documentation generation while human expertise ensures accuracy, clarity, and domain-specific nuance). The combination of social coordination and tool-assisted workflows creates a complementary rather than substitutive dynamic.
  
  \item \textbf{Digital Media Production.} Redirect toward digital media production programs, which demonstrate lower \NetRisk{} via elevated Physical dimension (hands-on production work, equipment operation) and Creativity dimension (multimedia storytelling, visual narrative). The physical and creative defense dimensions provide sheltering that pure writing-intensive programs lack, while maintaining narrative and content creation skills.
\end{itemize}

These absorber programs are justified by the model: each exhibits a \NetRisk{} profile more favorable than Writers and Authors due to higher \DefScore{} (particularly Social and Creativity dimensions) relative to \SubScore{}, indicating that GenAI serves as a complementary tool rather than a direct substitute for core competencies.

\section{Beyond employability: other success metrics}
\label{sec:other_factors}
Employability is necessary but not sufficient. We propose additional success metrics the prompt highlights: learning integrity and attribution compliance, equity/access, and sustainability (energy/water/compute cost). 

We formalize the trade-offs with a robust rule-based decision model that maps institution-specific constraints to three policy regimes: \textit{Ban} (restrict use in assessment), \textit{Allow-with-Audit} (permit with strict provenance), and \textit{Require} (integrate into workflow).
The rules consider:
\begin{itemize}
    \item \textbf{Exposure Risk:} If \(\NetRisk > 0\), GenAI is a substitute that threatens skill acquisition. This requires either \textit{Ban} (if audit capacity is low) or \textit{Allow-with-Audit} (if audit capacity is high).
    \item \textbf{Sheltering:} If \(\NetRisk < 0\), GenAI is a complement. We recommend \textit{Require} to capture productivity, unless sustainability is the dominant constraint (in which case \textit{Ban} or limit usage to save compute).
\end{itemize}

Table~\ref{tab:policy_regimes} summarizes the policy requirements. Table~\ref{tab:policy_decision} reports the resulting recommended policy per institution under alternative weight regimes (Balanced, Integrity-First, Sustainability-First). We test these rules against perturbations in risk scores and audit capacity estimates; Table~\ref{tab:policy_sensitivity} reports the stability of these recommendations.

\IfFileExists{tables/policy_regimes.tex}{\input{tables/policy_regimes.tex}}{}
\IfFileExists{tables/policy_decision.tex}{\input{tables/policy_decision.tex}}{}
\IfFileExists{tables/policy_sensitivity.tex}{\input{tables/policy_sensitivity.tex}}{}

\begin{figure}[H]
\centering
\includegraphics[width=0.8\linewidth]{figures/policy_tradeoff.png}
\caption{Policy trade-offs under balanced weights (generated from \texttt{data/policy\_decision\_scores.csv}).}
\label{fig:policy_tradeoff}
\end{figure}

\section{Generalization}
\label{sec:generalization}
The mechanism layer and scenario framework generalize to other programs by: (i) swapping the occupation(s), (ii) recomputing local OEWS context for the institution's region, and (iii) choosing scenario parameters \(s\) appropriate for the institution's risk tolerance. Institution-specific recommendations vary primarily through local labor market demand, program mission, and constraints (e.g., resources, accreditation, student population).

\section{Prompt coverage checklist}
\label{sec:checklist}
\begin{itemize}[leftmargin=*]
  \item \textbf{Grow/shrink programs and transitions:} Section~\ref{sec:recommendations}.
  \item \textbf{What to teach about GenAI (including energy/water + attribution):} Sections~\ref{sec:recommendations} and \ref{sec:other_factors}.
  \item \textbf{Other success metrics beyond employment and how recs change:} Section~\ref{sec:other_factors}.
  \item \textbf{Generalization beyond one institution/program:} Section~\ref{sec:generalization}.
\end{itemize}

\newpage
\section*{References}
\bibliographystyle{plainnat}
\bibliography{references}

% AI Use Report (does not count toward 25 pages)
\clearpage
\appendix
\section{Mechanism Layer Details}
\label{app:mechanism}
Table~\ref{tab:onet_elements_appendix} lists the specific O*NET elements (Importance scale) selected for each mechanism dimension.

\IfFileExists{tables/onet_elements_appendix.tex}{\input{tables/onet_elements_appendix.tex}}{}

\section*{AI Use Report}
\input{ai_use_report.tex}

\end{document}
