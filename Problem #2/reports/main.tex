%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% MCM/ICM LaTeX Template %%
%% 2026 MCM/ICM           %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[12pt]{article}

\usepackage{geometry}
\geometry{left=1in,right=0.75in,top=1in,bottom=1in}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\Problem}{F}
\newcommand{\Team}{2632903}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{newtxtext}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{newtxmath}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{fancyhdr}
\setlength{\headheight}{15pt}
\lhead{Team \Team}
\rhead{}
\cfoot{}
\usepackage{amsmath,amssymb}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{xurl}
\usepackage[breaklinks]{hyperref}
\usepackage{enumitem}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{siunitx}
\usepackage{longtable}
\usepackage[numbers]{natbib}
\let\origthebibliography\thebibliography
\renewcommand{\thebibliography}[1]{\origthebibliography{#1}\sloppy}

\hypersetup{colorlinks=true, linkcolor=blue, urlcolor=blue, citecolor=blue}
\sisetup{detect-weight=true, detect-family=true, group-separator={,}, group-minimum-digits=4}

% ---------- Convenience macros ----------
\newcommand{\NetRisk}{\ensuremath{\mathrm{NetRisk}}}
\newcommand{\SubScore}{\ensuremath{\mathrm{Sub}}}
\newcommand{\DefScore}{\ensuremath{\mathrm{Def}}}
\newcommand{\Emp}[1]{E_{#1}} % employment level at year
\newcommand{\gbase}{g_{\mathrm{base}}}
\newcommand{\gadj}{g_{\mathrm{adj}}}

% ---------- Auto-generated numeric macros (from CSV artifacts) ----------
% These are safe to include in the preamble (only \newcommand definitions).
\IfFileExists{tables/scenario_macros.tex}{\input{tables/scenario_macros.tex}}{}

% ---------- Auto-generated tables/figures (from build_report_artifacts.py) ----------
% NOTE: these files contain full LaTeX environments, so they must be \input
% inside the document body (not in the preamble).

\newtheorem{theorem}{Theorem}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{definition}{Definition}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
\graphicspath{{.}{figures/}}
\DeclareGraphicsExtensions{.pdf,.jpg,.tif,.png}

% ========== Summary Sheet (first page) ==========
\thispagestyle{empty}
\vspace*{-16ex}
\centerline{\begin{tabular}{*3{c}}
	\parbox[t]{0.3\linewidth}{\begin{center}\textbf{Problem Chosen}\\ \Large \textcolor{red}{\Problem}\end{center}}
	& \parbox[t]{0.3\linewidth}{\begin{center}\textbf{2026\\ MCM/ICM\\ Summary Sheet}\end{center}}
	& \parbox[t]{0.3\linewidth}{\begin{center}\textbf{Team Control Number}\\ \Large \textcolor{red}{\Team}\end{center}}	\\
	\hline
\end{tabular}}

%%%%%%%%%%% Begin Summary %%%%%%%%%%%
\label{page:summary_start}
\begin{itemize}[leftmargin=*, itemsep=0.25em, topsep=0.25em]
  \item \textbf{Careers + institutions.} Software Developers (SDSU), Electricians (LATTC), Writers \& Authors (Academy of Art). National results use employment-weighted SOC bundles (Table~\ref{tab:scenario_summary}).
  \item \textbf{Data \& audit.} BLS OEWS + EP + O*NET; independent reality-check vs AIOE: \(r=\AIOEPearson\), \(\rho=\AIOESpearman\) (Table~\ref{tab:external_benchmark}).
  \item \textbf{Model.} Define task shares \(\tau_i:=\SubScore_i=\frac{\mathrm{Writing}+\mathrm{ToolTech}}{2}\) and \(\delta_i:=\DefScore_i=\frac{\mathrm{Physical}+\mathrm{Social}+\mathrm{Creativity}}{3}\), so \(\NetRisk_i=\tau_i-\delta_i\). Our scenario mapping is
  \[
    \gadj=\gbase-s\max(\tau_i-\delta_i,0)+(\,m_i\,s\,)\max(\delta_i-\tau_i,0),\qquad 0\le m_i\le m_{\max}=0.2,
  \]
  where \(m_i\) is a \emph{capacity/demand-response limiter} (bottlenecks + diminishing returns) so uplift is structurally smaller than headwind. \textbf{Index use (avoid whiplash): we use \(\NetRisk_{\text{uncal}}\) (equal-weight) for mechanism explanation and \(\NetRisk_{\text{cal}}\) (calibrated) as the projection driver when available (else fall back to \(\NetRisk_{\text{uncal}}\)).} \textbf{Plain English: positive NetRisk = exposed share exceeds defenses (headwind); negative NetRisk = defenses exceed exposure (capped uplift).} \textbf{Calibration weights shown use a minimum-weight (interpretable) fit; sparse zero-weight optima are a collinearity artifact and do not change rankings.}
  \item \textbf{Headline findings (national 2034; SOC bundles).}\IfFileExists{tables/summary_headline_fragment.tex}{\input{tables/summary_headline_fragment.tex}}{ (see Table~\ref{tab:scenario_summary}).}\par
  \item \textbf{Recommendations.} SDSU CS: maintain/slight growth; LATTC Electric: grow capacity; Academy of Art Writing: consolidate/specialize toward higher-originality niches and editing/production workflows (Section~\ref{sec:recommendations}).
  \item \textbf{Limitations.} Scenarios treat \(s\) as a transparent stress-test knob (not a causal estimate); careers are small SOC bundles; local sizing uses scaled openings as a proxy: \(O_{\mathrm{local}}=O_{\mathrm{US}}\cdot \mathrm{EmpShare}_{\mathrm{local}}\cdot \min(\mathrm{LQ},\mathrm{cap})\) (Section~\ref{sec:robustness}).
\end{itemize}
\vspace{-3pt}
\begin{center}
\fbox{\begin{minipage}{0.97\textwidth}
\small
\textbf{Model pipeline:} \textbf{Data} (BLS EP baseline growth + openings; OEWS local context + wages; O*NET task dimensions; external benchmarks) \(\rightarrow\)
\textbf{Mechanism layer} (\(\SubScore,\DefScore\Rightarrow \NetRisk_{\text{uncal}}\) for explainability) \(\rightarrow\)
\textbf{Calibration} (fit \(\NetRisk_{\text{cal}}\) to external AI applicability; used for projections) \(\rightarrow\)
\textbf{Scenarios} (\(\gadj\) mapping; immediate + ramp adoption) \(\rightarrow\)
\textbf{Openings} (EP annual openings; local scaling with LQ + clipping) \(\rightarrow\)
\textbf{Recommendations} (program sizing + curriculum/policy).
\end{minipage}}
\end{center}
\vspace{-2pt}
{\scriptsize \ScenarioArtifactsStamp}
\label{page:summary_end}
%%%%%%%%%%% End Summary %%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\pagestyle{fancy}
\sloppy
\tableofcontents
\newpage
\setcounter{page}{1}
\rhead{Page \thepage\ }
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{page:toc_start}

% ============================================================
% Main report
% ============================================================
\section{Problem framing and choices}
\label{sec:framing}
We aim to advise leaders of three post-secondary programs on how to address GenAI, using a model grounded in public labor-market data and an O*NET mechanism layer. Our framing follows tasks-based technology theories: GenAI can substitute for some language/cognitive tasks while complementing others, changing task composition and productivity rather than deterministically eliminating whole occupations \citep{mit_tasks_based_framing, openai_llm_exposure, nber_generative_ai_at_work}. We choose the three careers to match the prompt's STEM/trade/arts categories and to span a wide range of task structures (software = tool/knowledge work; electricians = physical/manual, onsite; writers = writing-intensive creative production).
\par\textbf{Why these institutions} We pair each career with a real institution situated in a relevant labor market so recommendations are operational (Table~\ref{tab:local_context}): (i) SDSU is embedded in a large regional market for software and adjacent tech roles; (ii) LATTC is embedded in the Los Angeles construction/electrical labor market where apprenticeship pipelines are central; (iii) Academy of Art is embedded in the Bay Area creative economy where writing roles increasingly intersect with media production and content operations.

\section{Data and preprocessing}
\label{sec:data}
\subsection{BLS OEWS (local labor market context)}
OEWS provides local (state and metropolitan) employment and wage levels for occupations. We use these as the institution-specific context inputs: the `local'' employment level and wages for each program's regional labor market \citep{bls_oews_tec}.

\subsection{BLS Employment Projections (national baseline trend)}
EP provides national occupational employment projections over 2024--2034, which we convert to an annual baseline growth rate \(\gbase\). National trajectories use EP (all jobs) for consistency with baseline growth rates; OEWS (wage-and-salary) is used for local labor-market context. We use EP as the no-GenAI baseline trajectory for each focal career (aggregating across the SOCs in its bundle) \citep{bls_ep_table110}.

\subsection{O*NET mechanism layer (why substitution vs.\ complementarity)}
We use O*NET 30.1 `Importance'' ratings from Work Activities, Abilities, and Skills to construct five dimensions. We compute each dimension score per occupation and convert to a percentile across occupations (0--1). This produces interpretable inputs for \(\NetRisk\) \citep{onet_database, onet_taxonomy, onet_license}.

\paragraph{Attribution.} O*NET\textsuperscript{\textregistered} data used under the O*NET Database Content License; see References \citep{onet_license}.

\subsection{Crosswalks and coverage (what gets dropped)}
Occupational taxonomies differ between OEWS/EP (SOC-based) and O*NET (O*NET-SOC). We align them at the SOC occupation code level used in BLS tables by slicing O*NET-SOC codes (e.g., \texttt{15-1252.00}) to their 7-character SOC stem (e.g., \texttt{15-1252}). This merges multiple O*NET-SOC specialties into one SOC occupation, which is appropriate because BLS publishes OEWS/EP at the SOC level.\par
Not every SOC appears in every data source: some SOC codes present in O*NET do not appear in OEWS or EP tables (and vice versa), and some are aggregation/detail differences. Table~\ref{tab:mechanism_coverage} reports counts at each stage (O*NET-SOC $\to$ SOC slice $\to$ relevant elements $\to$ mechanism-scored occupations $\to$ overlap with OEWS/EP) so that any `dropped'' occupations are transparent and auditable.

\IfFileExists{tables/mechanism_coverage.tex}{\input{tables/mechanism_coverage.tex}}{}

\section{Model}
\label{sec:model}
\subsection{Mechanism dimensions}
Let \(d\in\{\mathrm{Writing},\mathrm{ToolTech},\mathrm{Physical},\mathrm{Social},\mathrm{Creativity}\}\) be the five dimensions. For each occupation \(i\), we compute a raw mean importance score from selected O*NET elements, then convert to a percentile across the occupation set:
\[
  x_{i,d} \in [0,1] \quad \text{(percentile among occupations)}.
\]

\subsubsection{Construct validity (what we capture vs.\ what we omit)}
Our five dimensions capture: (i) Writing and Tool/Tech capture tasks where GenAI can substitute for or accelerate codified language and computer-mediated workflows; (ii) Physical, Social, and Creativity capture defenses where outputs depend on onsite manipulation, interpersonal coordination, and originality/voice.\par
\textbf{What we omit.} For STEM roles in particular, GenAI exposure is not only about writing or tool use; it also interacts with \emph{system-level responsibility}: safety/liability, integration complexity, and the consequences of errors. These channels are hard to represent with a small, stable, public feature set without overfitting.\par
\textbf{Sensitivity check.} To address this construct-validity gap without expanding the core model, we add a sensitivity-only ``accountability/system responsibility'' channel from O*NET Work Context (consequence of error and impact of decisions) into the defense score and show our focal-career conclusions remain stable (Table~\ref{tab:mechanism_accountability_sensitivity}).\par
\textbf{Interpreting calibrated weights.} Because the five dimensions are correlated, nonnegative calibration can push a correlated dimension’s weight toward zero under the sparse optimum; we therefore report a \emph{minimum-weight} calibration as the headline (to avoid face-validity issues) and note that rankings are unchanged.

\subsection{Net Risk index}
Define substitution and defense scores:
\[
  \SubScore_i = \frac{x_{i,\mathrm{Writing}} + x_{i,\mathrm{ToolTech}}}{2}, \qquad
  \DefScore_i = \frac{x_{i,\mathrm{Physical}} + x_{i,\mathrm{Social}} + x_{i,\mathrm{Creativity}}}{3},
\]
and \(\NetRisk_i = \SubScore_i - \DefScore_i\). For the microfoundation spine, we interpret these as explicit task shares:
\[
  \tau_i := \SubScore_i \in [0,1] \quad \text{(AI-exposed/codified task share)}, \qquad
  \delta_i := \DefScore_i \in [0,1] \quad \text{(defense/complementarity share)}.
\]
Thus \(\NetRisk_i=\tau_i-\delta_i\) is the \emph{net exposed share}: positive \(\NetRisk\) implies exposed tasks dominate defenses (headwind), while negative \(\NetRisk\) implies defenses dominate exposure (potential uplift, but bounded by capacity/diminishing returns).

Table~\ref{tab:netrisk_summary} provides summary statistics for the \NetRisk{} distribution across all scored occupations, and the interpretation examples below illustrates the interpretation by listing extreme examples from both tails of the distribution.

\IfFileExists{tables/netrisk_summary.tex}{\input{tables/netrisk_summary.tex}}{}
\IfFileExists{tables/netrisk_interpretation.tex}{\input{tables/netrisk_interpretation.tex}}{}

\begin{figure}[H]
\centering
\includegraphics[width=0.9\linewidth]{figures/netrisk_hist.png}
\caption{Distribution of NetRisk scores across all occupations in the mechanism layer.}
\label{fig:netrisk_hist}
\end{figure}

\subsection{External calibration to AI applicability}
To improve rigor, we calibrate the mechanism weights against an external occupation-level AI applicability measure from the \emph{Working with AI} dataset (Tomlinson et al., 2025), which provides SOC-level applicability scores derived from real-world GenAI usage patterns \citep{tomlinson2025working}. We fit nonnegative weights on the five dimensions with defense dimensions entering with negative sign. Because the five dimensions are correlated, the nonnegativity constraint can yield sparse solutions (some weights at or near zero), which should be interpreted as ``adds little predictive power given the other dimensions'' rather than ``dimension is irrelevant.''\par
In other words, multiple dimensions can be jointly informative but redundant: when two percentile features move together across occupations, the constrained fit may assign weight primarily to one and drive the other toward zero without meaning that the underlying mechanism is absent. We therefore treat any single fitted weight vector as a summary rather than a mechanistic truth.\par
To reconcile interpretability vs.\ prediction, we explicitly report \textbf{two} indices: (i) the equal-weight mechanism index \(\NetRisk_{\text{uncal}}\) (used for the substitution/defense narrative), and (ii) the calibrated predictive index \(\NetRisk_{\text{cal}}\) (used for scenario projections when available). Table~\ref{tab:netrisk_index_compare} quantifies how closely these indices align.\par
The calibrated weights define \(\NetRisk_{\text{cal}}\) by taking the signed weighted sum, centering it to mean zero across occupations, and rescaling to approximately \([-1,1]\). When calibration outputs are available, the pipeline uses \(\NetRisk_{\text{cal}}\) in downstream scenario projections; otherwise it uses \(\NetRisk_{\text{uncal}}\).

\IfFileExists{tables/calibration_interpretability.tex}{\input{tables/calibration_interpretability.tex}}{}
\IfFileExists{tables/calibration_summary.tex}{\input{tables/calibration_summary.tex}}{}
Table~\ref{tab:calibration_interpretability} reports the feature correlation matrix and the headline (minimum-weight) calibration weights. The sparse optimum (Table~\ref{tab:calibration_summary}) is included for reference only; rankings are unchanged.
\IfFileExists{tables/netrisk_index_compare.tex}{\input{tables/netrisk_index_compare.tex}}{}
\par\textbf{Note on index differences.} The calibrated and uncalibrated indices are strongly aligned overall (Table~\ref{tab:netrisk_index_compare}); for space, we omit extended disagreement examples.

\begin{figure}[H]
\centering
\includegraphics[width=0.6\linewidth]{figures/calibration_scatter.png}
\caption{Calibration fit: observed vs.\ predicted AI applicability.}
\label{fig:calibration_scatter}
\end{figure}

\subsection{Scenario employment projection}
Let \(\Emp{2024}\) be the 2024 employment level used for the projection base (from BLS EP for national scenarios) and \(\gbase\) the EP annual baseline growth. OEWS is used for \emph{local} labor market context and program sizing (Section~\ref{sec:recommendations}). For a scenario parameter \(s\ge 0\), define adjusted growth:
\[
  \gadj = \gbase - s\cdot\max(\NetRisk,0) + (\,m_i\,s\,)\cdot\max(-\NetRisk,0)
\]
\begin{center}
\fbox{\begin{minipage}{0.97\textwidth}
\small
\textbf{Microfoundation spine (task shares $\rightarrow$ effective exposure $\rightarrow$ growth mapping).}
\emph{Step 1: define task shares from the mechanism layer.} Let
\[
  \tau_i := \SubScore_i \in [0,1] \quad \text{(AI-exposed/codified share)},\qquad
  \delta_i := \DefScore_i \in [0,1] \quad \text{(defense/complementarity share)},
\]
so \(\NetRisk_i=\tau_i-\delta_i\). We interpret \(\delta_i\) as a structural \emph{offset} to exposure: tasks that are physical/onsite, highly social, or originality-driven are harder to automate and/or turn GenAI into a productivity tool rather than a substitute.\par
\emph{Step 2: substitution headwind scales with net exposed share.} Let \(A_i\in[0,1]\) be adoption intensity by 2034 and \(r_i\in[0,1]\) the fraction of exposed tasks that become effectively automatable/time-saving. A reduced-form productivity shift on the exposed block is
\[
  \Delta \ln \mathrm{Prod}^{(\text{sub})}_i \approx A_i\,r_i\,(\tau_i-\delta_i)_+,
\]
If cost reductions pass through and output demand has elasticity \(\varepsilon_i\), then (linearizing) employment responds as
\[
  \Delta \ln L_i \approx (\varepsilon_i-1)\,\Delta \ln \mathrm{Prod}^{(\text{sub})}_i \approx (\varepsilon_i-1)\,A_i\,r_i\,(\tau_i-\delta_i)_+.
\]
This yields an annualized growth headwind/uplift over a decade:
\[
  \Delta g_i^{(\text{headwind})} \approx \frac{(\,1-\varepsilon_i\,)\,A_i\,r_i}{10}\;(\tau_i-\delta_i)_+.
\]
\textbf{Step 3: complementarity uplift is bounded by capacity and diminishing returns.} When \(\delta_i>\tau_i\), GenAI is more likely to act as a tool on the defended block (better planning, diagnostics, documentation, coordination), but realized demand-side uplift is \emph{bottlenecked}: physical throughput, credentialing/apprenticeship pipelines, and organizational capacity limit how much extra quantity can be produced/sold within a decade. We encode this with a conservative multiplier \(m_i\in[0,m_{\max}]\) and treat \(m_{\max}<1\) as a structural asymmetry constraint (uplift smaller than headwind).\par
\textbf{Operationalizing the bound.} We set
\[
  m_i=\min\{m_{\max},(1-B_i)\tilde{\varepsilon}_i\},
\]
where \(B_i\in[0,1]\) is a bottleneck index (Physical percentile + coarse licensing proxy by SOC major group) and \(\tilde{\varepsilon}_i\in[0,1]\) is a conservative demand-responsiveness proxy (binned by SOC major group; not a literal elasticity). This makes the \emph{sign asymmetry structural}: uplift is limited by scaling constraints, so \(m_i\le m_{\max}\ll 1\).\par
\textbf{One interpretable wedge } Define
\[
  \kappa_i := (\,1-\varepsilon_i\,)\,A_i\,r_i \in [0,1],
\]
so \(\Delta g_i^{(\text{headwind})} \approx \frac{\kappa_i}{10}(\tau_i-\delta_i)_+\) and our scenario knob remains
\[
  s \approx \kappa/10.
\]
This keeps the scenario mapping unchanged while making the knob interpretable as a \emph{defensible prior} over adoption $\times$ automability $\times$ demand-response wedge (Tables~\ref{tab:scenario_params} and \ref{tab:scenario_param_priors}).\par

\textbf{Mechanical reproduction of the chosen \(s\) values.} Empirically, \(p90(\tau \mid \NetRisk>0)=\TauPninetyPosNetRisk\) in our scored mechanism layer. Targeting \(\Delta g_{p90}=0.015\) (Moderate) and \(0.03\) (High), the microfoundation implies
\[
  \kappa = \frac{10\,\Delta g_{p90}}{\tau_{p90}}.
\]
Thus Moderate gives \(\kappa\approx\KappaFromTauPninetyModerate\Rightarrow s\approx\SFromTauPninetyModerate\), and High gives \(\kappa\approx\KappaFromTauPninetyHigh\Rightarrow s\approx\SFromTauPninetyHigh\), which is close to the implemented pipeline values \(s_{\text{Moderate}}=\sModerateSubstitution\) and \(s_{\text{High}}=\sHighDisruption\) (Table~\ref{tab:scenario_params}). Table~\ref{tab:scenario_kappa_implied} reports the implied \(\kappa=10s\) under those same scenario strengths for transparency.
\end{minipage}}
\end{center}
We use the microfoundation to interpret \(s\) (units and magnitude), while \(\NetRisk=\tau-\delta\) supplies the signed direction. Table~\ref{tab:comp_cap_components} reports the bottleneck and demand-response components used to compute \(m_i\).\par
\IfFileExists{tables/comp_cap_components.tex}{\input{tables/comp_cap_components.tex}}{}
\IfFileExists{tables/comp_cap_major_groups.tex}{\input{tables/comp_cap_major_groups.tex}}{}
\IfFileExists{tables/comp_factor_sensitivity.tex}{\input{tables/comp_factor_sensitivity.tex}}{}
\textbf{Numeric anchor for \(m_{\max}=0.2\).} We choose \(m_{\max}\) so that even under High disruption, the implied \emph{maximum} annual uplift for a strongly sheltered occupation remains well below 1\%/yr. For example, for Electricians (bundle \(\NetRisk\approx-0.888\)) under High (\(s_{\text{High}}=0.0375\); Table~\ref{tab:scenario_params}), the uplift term is bounded by
\[
  \Delta g_{\text{uplift}} \le m_{\max}\,s_{\text{High}}\,|\NetRisk|
  = 0.2 \cdot 0.0375 \cdot 0.888 \approx 0.0067 \quad (\approx 0.67\%\text{/yr}),
\]
which cumulates to \(\lesssim 6.8\%\) extra employment over 10 years. In our base bottleneck/elasticity construction, Electricians have \(m_{\mathrm{eff}}\approx 0.01\) (Table~\ref{tab:comp_cap_components}), so the realized uplift is far smaller than the 0.67\%/yr upper bound. Thus, even at High disruption, complementarity can add at most sub-1\% annual growth for strongly sheltered occupations, preventing implausible booms from the uplift channel alone.\par
Why calibrate to the \(p90\) tail? Anchoring Moderate/High at \(p90(\NetRisk_+)\) (instead of the maximum) targets ``highly exposed but not extreme'' occupations, yielding a stable reference point that is less sensitive to outliers and measurement noise while still representing the upper-risk tail.\par
\textbf{Outside evidence for the anchor magnitudes.} Task-level and firm-level studies of deployed GenAI typically find \emph{double-digit} productivity gains on suitable tasks. For example, in a field setting with 5,172 customer-support agents, \citet{brynjolfsson2025genaiwork} find roughly a 15\% increase in issues resolved per hour on average after introducing a GenAI assistant (with larger gains for less experienced workers). In a preregistered experiment on professional writing tasks, \citet{noy2023experimental} find a 40\% reduction in time-to-completion and an 18\% increase in output quality when participants can use ChatGPT.\par
\textbf{Translating to our wedge \(\kappa=(1-\varepsilon)Ar\).} Interpreting these studies as plausible \emph{task-time/throughput} effects conditional on effective use suggests \(Ar\) on the order of \(0.15\) (conservative) up to \(0.50\) (aggressive) for highly exposed work by 2034, depending on adoption saturation and how much of the exposed block is actually time-saving. With a conservative demand-response wedge \(1-\varepsilon\in[0.3,0.8]\), this implies \(\kappa\approx(1-\varepsilon)Ar\in[0.05,0.40]\). Our Moderate/High anchors correspond to \(\kappa\approx\KappaFromTauPninetyModerate\) and \(\kappa\approx\KappaFromTauPninetyHigh\) via \(\kappa=10\Delta g_{p90}/\tau_{p90}\), placing them within an empirically motivated range while still being used transparently as \emph{stress-test} magnitudes rather than causal estimates.\par
Scenario strengths are defined by this reference-point calibration: we target a growth headwind of 1.5\% (Moderate) or 3\% (High) for the 90th percentile of the \emph{positive} \(\NetRisk\) distribution. Concretely, the pipeline computes \(p90(\NetRisk_+)\) from the calibrated mechanism layer, then sets
\[
  s_{\text{Moderate}} = 0.015 / p90(\NetRisk_+), \qquad s_{\text{High}} = 0.03 / p90(\NetRisk_+),
\]
so that the 90th-percentile exposed occupation experiences the intended annual headwind under the piecewise mapping. Table~\ref{tab:scenario_params} reports the scenario parameters actually used (including whether they came from calibration outputs or defaults). We project 2034 employment as \(\Emp{2034} = \Emp{2024}(1+\gadj)^{10}\). We treat \(s\) as a scenario knob rather than an estimated causal effect; Section~\ref{sec:robustness} reports a sensitivity grid.

\IfFileExists{tables/scenario_params.tex}{\input{tables/scenario_params.tex}}{}
\IfFileExists{tables/scenario_param_priors.tex}{\input{tables/scenario_param_priors.tex}}{}
\IfFileExists{tables/scenario_kappa_implied.tex}{\input{tables/scenario_kappa_implied.tex}}{}

\subsection{Definitions \& Provenance}
\label{sec:definitions_provenance}
\textbf{Two NetRisk indices (reported side-by-side).}
\begin{itemize}[leftmargin=*]
  \item \textbf{NetRisk (uncalibrated; mechanism/interpretability index).} Defined from O*NET percentile scores:
  \[
    \NetRisk_{\text{uncal}}=\underbrace{\frac{\mathrm{Writing}+\mathrm{ToolTech}}{2}}_{\SubScore}-\underbrace{\frac{\mathrm{Physical}+\mathrm{Social}+\mathrm{Creativity}}{3}}_{\DefScore}.
  \]
  This equal-weight form is used to \emph{explain} substitution vs.\ defense mechanisms (what drives risk).
  \item \textbf{NetRisk (calibrated; predictive index).} A signed weighted sum calibrated to an external occupation-level AI applicability score (Tomlinson et al., 2025), then centered and rescaled to approximately \([-1,1]\). Because the O*NET dimensions are correlated and weights are constrained nonnegative, calibration can push one of a correlated pair (e.g., Writing vs.\ Tool/Tech) toward zero without implying the underlying mechanism is absent.
  \item \textbf{Which index drives scenarios?} Scenario projections use \textbf{calibrated NetRisk when available}; otherwise they fall back to the uncalibrated index. Table~\ref{tab:netrisk_index_compare} summarizes alignment between indices.
\end{itemize}

\textbf{What drives scenarios (national 2024--2034).}
\begin{itemize}[leftmargin=*]
  \item \textbf{Baseline trajectory.} $E_{2024}$ and baseline growth $\gbase$ come from BLS Employment Projections (EP). Baseline 2034 is $E_{2034}=E_{2024}(1+\gbase)^{10}$.
  \item \textbf{Disruption mapping.} We adjust growth with a transparent scenario knob $s$:
  \[
    \gadj = \gbase - s\cdot\max(\NetRisk,0) + (\,m_i\, s\,)\cdot\max(-\NetRisk,0), \qquad 0\le m_i \le m_{\max}=0.2,
  \]
  and project $E_{2034}=E_{2024}(1+\gadj)^{10}$. \textbf{Ramp} scenarios phase in disruption with a logistic diffusion curve $s(t)$ (S-curve) scaled so that $s(2024)=0$ and $s(2034)=s$, with adoption timing allowed to differ by career (software earlier than trades).
  \item \textbf{How Moderate/High are set.} When calibration outputs exist, we set $s$ so that the 90th percentile of the positive NetRisk tail experiences a $1.5\%$ (Moderate) or $3.0\%$ (High) annual growth headwind; the exact values used are reported in Table~\ref{tab:scenario_params}.
\end{itemize}

\textbf{What a “career bundle” contains (SOC occupations; EP employment weights).}
\footnotesize
\IfFileExists{tables/bundle_contents_fragment.tex}{\input{tables/bundle_contents_fragment.tex}}{}

\section{Results}
\label{sec:results}
\begin{center}
\fbox{\begin{minipage}{0.97\textwidth}
\small
\textbf{NetRisk legend (to avoid index whiplash).} We report \textbf{$\NetRisk_{\text{uncal}}$} for mechanism interpretation and stability checks, and \textbf{$\NetRisk_{\text{cal}}$} as the projection driver when calibration is available (otherwise scenarios fall back to $\NetRisk_{\text{uncal}}$).
\end{minipage}}
\end{center}
\IfFileExists{tables/netrisk_focal_compare.tex}{\input{tables/netrisk_focal_compare.tex}}{}

\subsection{National outcomes for the three careers}
Each career is represented by a small bundle of SOC occupations (e.g., 2--3 codes per career); outcomes are employment-weighted over the bundle so that larger occupations contribute more to the career-level projection. Table~\ref{tab:scenario_summary} reports baseline vs.\ disruption outcomes and the \(\NetRisk\) range (min--max across the bundle) as a robustness check.
\par\textbf{Two scenario anchors.} We report both (i) \textbf{Global Moderate/High} scenarios using a single shock parameter \(s\) calibrated at the high-exposure tail (an upper-bound stress test), and (ii) \textbf{Career-prior Moderate/High} scenarios using career-specific \(s_i\approx \kappa_i/10\) implied by the microfoundation wedge priors (Table~\ref{tab:scenario_param_priors}). The career-prior columns are intended as the \emph{most plausible} magnitude checks; the global columns are conservative stress tests for planning under uncertainty. \textbf{For trades in particular, the global scenarios are intentionally conservative upper-bound stress tests; the career-prior columns are the plausible magnitude check.}

\IfFileExists{tables/scenario_summary.tex}{\input{tables/scenario_summary.tex}}{}
\IfFileExists{tables/bundle_soc_breakdown.tex}{\input{tables/bundle_soc_breakdown.tex}}{}

\begin{figure}[H]
\centering
\includegraphics[width=0.98\textwidth]{figures/visual_spine.png}
\caption{Visual spine for judge skimming: (left) NetRisk distribution with markers for the three careers, (middle) scenario outcomes for 2034 employment, and (right) institution recommendation summary.}
\label{fig:visual_spine}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth,keepaspectratio]{figures/scenario_bar.png}
\caption{2034 employment for the three careers under baseline, moderate, and high disruption.}
\label{fig:scenario_bar}
\end{figure}

\subsection{Dynamic Adoption}
The scenarios above assume immediate adoption of GenAI at full impact. In reality, adoption ramps gradually and often follows an S-curve (slow initial diffusion, then rapid uptake, then saturation). Table~\ref{tab:scenario_summary} therefore includes `Ramp Moderate'' and `Ramp High'' scenarios that phase in disruption with a logistic diffusion curve $s(t)$, scaled so that $s(2024)=0$ and $s(2034)$ matches the same Moderate/High severity used in the immediate scenarios. We allow adoption timing to differ by career (e.g., software earlier than trades) as a realistic mechanism rather than an extra free parameter. Across all three careers, ramp outcomes lie between baseline and immediate-disruption outcomes, implying institutions have a window to adapt curricula and assessment as adoption accelerates.
\begin{table}[H]
\centering
\caption{Career-specific adoption curve parameters used for ramp scenarios (logistic midpoint \(t_0\) and slope \(k\)).}
\label{tab:adoption_params}
\begin{tabular}{lrr}
\toprule
Career & \(t_0\) & \(k\)\\
\midrule
Software Developers & 2027.5 & 1.10\\
Electricians & 2029.5 & 0.70\\
Writers and Authors & 2027.0 & 0.95\\
\bottomrule
\end{tabular}
\end{table}

\subsection{Job openings and program sizing}
Beyond net employment growth, annual job openings drive training demand. Table~\ref{tab:openings_summary} reports annual openings from EP projections and their implications for program sizing decisions.

\IfFileExists{tables/openings_summary.tex}{\input{tables/openings_summary.tex}}{}

\subsection{Sensitivity and sanity checks}
\label{sec:robustness}
We conduct robustness checks to validate the stability of our model components; for space, we report only the checks that directly support judge-critical credibility (sign stability, calibration stability, and one independent external reality check).

\subsubsection{Mechanism Layer Stability}
The O*NET mechanism layer relies on specific descriptor choices and normalization methods. To test structural stability, we perturbed the descriptor set (leave-one-out) and tested alternative normalization (percentiles, z-score mapped to \([0,1]\) via Normal CDF, min--max scaling, and within-major-group ranks). Table~\ref{tab:mechanism_sensitivity} summarizes the results: the sign of \(\NetRisk\) for our three focal careers remains stable across perturbations, confirming that the classification of careers as ``exposed'' vs.\ ``sheltered'' is not an artifact of specific element selection.

\IfFileExists{tables/mechanism_sensitivity.tex}{\input{tables/mechanism_sensitivity.tex}}{}
\IfFileExists{tables/mechanism_accountability_sensitivity.tex}{\input{tables/mechanism_accountability_sensitivity.tex}}{}

\subsubsection{Calibration Validation}
We validate the calibration weights using 5-fold cross-validation and bootstrap resampling (Table~\ref{tab:calibration_validation}). The model achieves stable out-of-sample performance, and bootstrap analysis confirms that the negative weights on defense dimensions are statistically robust. We also compare the calibrated index against an uncalibrated (equal-weight) baseline; the ranking of focal careers is preserved, though the magnitude of separation increases under calibration.

\IfFileExists{tables/calibration_validation.tex}{\input{tables/calibration_validation.tex}}{}

\subsubsection{External benchmark reality check}
As an additional independent check, we compare our NetRisk indices against a published occupation-level AI exposure measure: the AI Occupational Exposure (AIOE) dataset of \citet{felten2021aioe}. We report the correlation of both the uncalibrated mechanism index and the calibrated predictive index with AIOE (Table~\ref{tab:external_benchmark}). Because these measures were constructed with different assumptions and targets, perfect agreement is not expected; we use this check to ensure our ranking is broadly plausible.

\IfFileExists{tables/external_benchmark.tex}{\input{tables/external_benchmark.tex}}{}
\par\textbf{Interpretation.} Because these exposure measures target different constructs, perfect agreement is not expected; the correlation is used as a plausibility check rather than a requirement for pointwise agreement.

\subsubsection{Scenario and Parameter Sensitivity}
Scenario outcomes vary with the severity knob \(s\), but the \emph{direction} of impact by career is structurally determined by the mechanism layer. We therefore report a single uncertainty summary for 2034 outcomes under Moderate and High disruption (Table~\ref{tab:uncertainty_summary}) and omit extended grids and auxiliary sensitivity tables for space.

\IfFileExists{tables/uncertainty_summary.tex}{\input{tables/uncertainty_summary.tex}}{}

\subsubsection{Local openings scaling robustness}
Local program sizing requires scaling national EP annual openings to a metro/state labor market. Because location quotients (LQ) already encode relative local concentration, multiplying both a local occupation-share factor and LQ can double-count concentration. We therefore use the standard decomposition (local total employment share $\times$ LQ) with conservative clipping for planning.

\section{Institution-specific recommendations}
\label{sec:recommendations}
Recommendations are organized to answer the prompt: (i) whether to grow or shrink program size and how, and (ii) what to teach about GenAI to best support employability, tied back to model outputs and local context.
\par\textbf{Wages.} Our scenarios project \emph{employment levels}, not wages. However, GenAI adoption can shift the \emph{composition} of work toward higher-responsibility ``verifier/overseer'' tasks (testing, security, compliance, QA, editorial judgment, and provenance). When such verifier-type skills become the binding constraint, \emph{wage premia can rise even if employment growth slows}. This motivates our curriculum emphasis on verification and accountability: software programs should prioritize testing/security/evaluation; electrician programs should prioritize code-compliance documentation and diagnostic reasoning; writing programs should emphasize editing, provenance, and production workflows where human judgment remains scarce.

\paragraph{Common policy framework (Integrity / Access / Sustainability).}
\begin{itemize}[leftmargin=*]
  \item \textbf{Integrity / attribution.} Require disclosure (tools + prompts/versions) for graded work when AI use is permitted; use oral defenses and in-class components for authenticity.
  \item \textbf{Equity / access.} Do not require paid subscriptions; provide institution-supported accounts and lab workflows, with accessibility accommodations.
  \item \textbf{Sustainability.} Prefer efficient workflows (editing-first, retrieval, smaller/local models when feasible); set reasonable limits on high-compute generation.
\end{itemize}

\paragraph{Policy decision rule (why these recommendations).}
We evaluate policy/curriculum regimes using a simple multi-criteria rule that explicitly includes \textbf{equity/access} alongside integrity and sustainability, using transparent proxy inputs (e.g., assessment/auditability burden, student access to tooling, and operational resource constraints). Each component is scored on \([0,1]\). We treat Employability \(E\) and Access \(A\) as \emph{benefits} (higher is better), while Integrity \(I\) and Sustainability \(S\) are \emph{risks/costs} (higher is worse). To keep the objective judge-readable (no negative totals), we score policies using an all-positive benefit form:
\[
  \text{Score} = w_E E + w_I(1-I) + w_S(1-S) + w_A A.
\]
The Balanced objective uses equal weights \(w_E=w_I=w_S=w_A=1\), so \(\text{Score}\in[0,4]\). Table~\ref{tab:policy_decision_compact} reports the regime scores under the Balanced objective and the within-institution argmax.

\IfFileExists{tables/policy_decision_compact.tex}{\input{tables/policy_decision_compact.tex}}{}

Table~\ref{tab:local_context} provides local labor market context including location quotients (LQ). We define an auxiliary \textit{Attractiveness Score} to inform positioning:
\[ \text{Attractiveness} = 0.4 \cdot (\text{Wage Premium}) + 0.3 \cdot (\text{Normalized Local Emp}) + 0.3 \cdot (\text{Normalized LQ}) \]
where normalized employment and LQ are min-max scaled across the three institutions. Table~\ref{tab:program_sizing} provides quantitative guidance on program sizing (annual intake) derived from estimated local annual openings. Local openings are computed from national EP openings using a standard decomposition (local total employment share $\times$ LQ, with conservative clipping). To account for uncertainty in program efficiency (completion rates and placement rates), we report recommended intake ranges rather than single point estimates.
To make these ranges feel grounded beyond model outputs, we also include a small public \emph{reality-check anchor} per program (e.g., recent completions or a close proxy; used for context only, not as a fitted input) in Table~\ref{tab:program_anchor}.
Why target 5\% / 10\% / 15\% of local openings? These shares are not claims about market power; they are \emph{planning heuristics} spanning realistic capacity regimes: 5\% represents a conservative seat target for resource-constrained programs, 10\% is an aspirational ``steady-state'' target for a strong regional program with sustained placement partnerships, and 15\% represents an aggressive expansion scenario (e.g., additional faculty/labs, expanded apprenticeships) that may be feasible for high-demand fields. The resulting seat ranges translate openings into intake while explicitly accounting for completion$\times$placement uncertainty.

\IfFileExists{tables/program_sizing_compact.tex}{\input{tables/program_sizing_compact.tex}}{}

\subsection{SDSU (Software Developers)}
\textbf{Program size.} Maintain or modestly grow cohorts; disruption primarily reduces growth rate rather than reversing demand (Table~\ref{tab:scenario_summary}). For planning, we recommend \textbf{10\% share as the baseline} (Table~\ref{tab:program_sizing}), with 15\% as an expansion case; this aligns with the public completion anchor (Table~\ref{tab:program_anchor}).\par
\textbf{Curriculum.} Shift emphasis from boilerplate coding to system design, testing, security, and AI-assisted development with audit trails; make students fluent in evaluating and verifying model outputs.\par
\textbf{Policy.} Permit GenAI use in advanced courses with required disclosure and reproducibility; constrain use in early courses to ensure fundamentals.\par
\textbf{Policy constraints.} Apply the common framework above; SDSU’s key delta is assessment design that forces verification (tests/CI, reproducibility, and audit trails) rather than polished outputs.
\par\textbf{Concrete actions.}
\begin{itemize}[leftmargin=*]
  \item \textbf{AI-assisted software engineering rubric.} Require every capstone/upper-division project to include (i) tests and CI, (ii) a model-output verification checklist, and (iii) an AI usage disclosure appendix.\newline
  \emph{Metric:} \% of submissions with passing test suites; defect rate in instructor code review; disclosure compliance rate.
  \item \textbf{Model evaluation and security module.} Add a short required module on prompt injection, data leakage, licensing/IP, and evaluation design.\newline
  \emph{Metric:} performance on a standardized red-team + verification assessment (before/after module).
  \item \textbf{Assessment design resilient to GenAI.} Increase oral defenses and timed debugging tasks in core courses.\newline
  \emph{Metric:} gap between in-person performance and take-home performance (reduced variance indicates more robust assessment).
\end{itemize}

\subsection{LATTC (Electricians)}
\textbf{Program size.} Grow capacity and apprenticeship pathways; the career is sheltered by high physical/manual defense and remains strong across scenarios (Table~\ref{tab:scenario_summary}). For planning, we recommend \textbf{5\% share as the near-term baseline} (Table~\ref{tab:program_sizing}), with 10\% as an expansion case contingent on employer/apprenticeship capacity; current completions are far below the 10\% implied intake (Table~\ref{tab:program_anchor}).\par
\textbf{Curriculum.} Double down on hands-on competencies while adding `AI as a tool'' modules for diagnostics, scheduling, documentation, and code-compliant planning.\par
\textbf{Policy.} Teach safe, privacy-preserving, low-compute uses (templates, checklists) appropriate for small contractors.\par
\textbf{Policy constraints.} Apply the common framework above; LATTC’s key delta is keeping evaluation performance-based (hands-on practicals) and requiring code-compliance verification for any AI-assisted documentation.
\par\textbf{Concrete actions.}
\begin{itemize}[leftmargin=*]
  \item \textbf{AI-assisted job documentation.} Require students to produce work orders, inspection-ready notes, and material lists using structured templates (GenAI optional) with verification against NEC/local code excerpts.\newline
  \emph{Metric:} documentation completeness score; code-compliance error rate on practical exams.
  \item \textbf{Diagnostic reasoning labs.} Use fault-tree exercises where students must justify each step (GenAI permitted as a tutor, not as an answer key).\newline
  \emph{Metric:} time-to-diagnosis and accuracy on standardized fault scenarios; safety-critical mistake rate.
  \item \textbf{Apprenticeship alignment.} Expand employer partnerships to target annual seats suggested by local openings (Table~\ref{tab:program_sizing}).\newline
  \emph{Metric:} placement rate into apprenticeships; employer satisfaction survey on graduates' documentation and troubleshooting skills.
\end{itemize}

\subsection{Academy of Art University (Writers and Authors)}
\textbf{Program size.} Consolidate and specialize toward higher-originality work and editing/production roles; high disruption can flip the field to contraction (Table~\ref{tab:scenario_summary}). For planning, we recommend \textbf{5\% share as the baseline} (Table~\ref{tab:program_sizing}), with 10\% only as a long-run target if the program successfully pivots toward absorber roles (editing/technical writing/content operations) and can document placement outcomes; this is consistent with the public completion anchor (Table~\ref{tab:program_anchor}).\par
\textbf{Curriculum.} Emphasize narrative strategy, editing, and provenance-aware workflows. Teach students to use GenAI as a draft accelerator while differentiating through voice, revision quality, and IP-aware sourcing.\par
\textbf{Policy.} Require disclosure and provenance in portfolios; adopt rubrics that reward originality and documented creative process.\par
\textbf{Policy constraints.} Apply the common framework above; AAU’s key delta is a stricter default (ban in assessment-heavy courses unless provenance auditing is feasible), with grading centered on revision quality and documented process.
\par\textbf{Why the writing ``career bundle'' includes Editors and Technical Writers.}
\begin{center}
\fbox{\begin{minipage}{0.97\textwidth}
\small
We model ``Writers \& Authors'' as an \emph{adjacent labor market} bundle (SOC 27-3043 Writers and Authors, 27-3041 Editors, 27-3042 Technical Writers) because writing-program graduates frequently compete for and transition into editing, technical communication, and content-operations roles. These occupations share core writing/editing task foundations and are plausible absorber markets when pure authorship roles contract. As a robustness check, we also ran the projections using only SOC 27-3043; conclusions were qualitatively similar (not shown for space).
\end{minipage}}
\end{center}
\par\textbf{Concrete actions.}
\begin{itemize}[leftmargin=*]
  \item \textbf{Portfolio provenance standard.} Require every portfolio piece to include a process log (outline $\to$ drafts $\to$ revisions) and a disclosure statement for any tool-assisted content.\newline
  \emph{Metric:} \% of portfolio pieces with complete provenance; rubric scores on originality/voice and revision quality.
  \item \textbf{Editing and production track.} Create an explicit concentration in editing, story development, and content production workflows where human judgment is primary.\newline
  \emph{Metric:} internship/placement share into editing, producer-assistant, UX/technical writing, or content operations roles.
  \item \textbf{Assessment designed for authenticity.} Use in-class writing sprints and oral defenses (students explain intent, sources, and revision decisions).\newline
  \emph{Metric:} integrity-incident rate; inter-rater reliability of originality scoring.
\end{itemize}

\subsubsection{Transition Plan}
For students currently enrolled in the Writers and Authors program, we recommend redirecting to absorber programs with lower \NetRisk{} due to higher tool complementarity and stronger defense dimensions. Specific transition pathways include:

\begin{itemize}[leftmargin=*]
  \item \textbf{UX Writing.} Redirect students toward user experience writing programs, which exhibit lower \NetRisk{} due to higher \DefScore{} components: elevated Social dimension (user research, cross-functional collaboration) and Creativity dimension (design thinking, user-centered storytelling). The Writing component remains relevant but is complemented by collaborative and research-intensive workflows that GenAI augments rather than substitutes.
  
  \item \textbf{Technical Communication.} Transition students to technical communication programs, which show reduced \NetRisk{} through higher Social dimension scores (stakeholder communication, documentation for diverse audiences) and ToolTech complementarity (GenAI assists in documentation generation while human expertise ensures accuracy, clarity, and domain-specific nuance). The combination of social coordination and tool-assisted workflows creates a complementary rather than substitutive dynamic.
  
  \item \textbf{Digital Media Production.} Redirect toward digital media production programs, which demonstrate lower \NetRisk{} via elevated Physical dimension (hands-on production work, equipment operation) and Creativity dimension (multimedia storytelling, visual narrative). The physical and creative defense dimensions provide sheltering that pure writing-intensive programs lack, while maintaining narrative and content creation skills.
\end{itemize}

These absorber programs are justified by the model: each exhibits a \NetRisk{} profile more favorable than Writers and Authors due to higher \DefScore{} (particularly Social and Creativity dimensions) relative to \SubScore{}, indicating that GenAI serves as a complementary tool rather than a direct substitute for core competencies.


\bibliographystyle{plainnat}
\bibliography{references}

% AI Use Report (does not count toward 25 pages)
\clearpage
\section*{AI Use Report}
\input{ai_use_report.tex}

\end{document}
